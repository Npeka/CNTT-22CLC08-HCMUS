{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c82b9d2f-ef2c-4d83-b6d9-79cad715479b",
   "metadata": {},
   "source": [
    "# HW2: Softmax Regression\n",
    "\n",
    "(Cập nhật lần cuối: 28/10/2024)\n",
    "\n",
    "Họ tên: ...\n",
    "\n",
    "MSSV: ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b031f42-d6e2-471f-82bb-7e5b84f95065",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d021293f-5ce3-41a7-a2ec-0fe3ffd4af0d",
   "metadata": {},
   "source": [
    "## Nắm cách làm bài và nộp bài"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f089d0a-4111-4222-8762-d08d6096acf7",
   "metadata": {},
   "source": [
    "&#9889; Bạn lưu ý là mình sẽ dùng chương trình hỗ trợ chấm bài nên bạn cần phải tuân thủ chính xác qui định mà mình đặt ra, nếu không rõ thì hỏi, chứ không nên tự tiện làm theo ý của cá nhân.\n",
    "\n",
    "**Cách làm bài**\n",
    "\n",
    "Bạn sẽ làm trực tiếp trên file notebook này. Đầu tiên, bạn điền họ tên và MSSV vào phần đầu file ở bên trên. Trong file, bạn làm bài ở những chỗ có ghi là:\n",
    "```python\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "```\n",
    "hoặc đối với những phần code không bắt buộc thì là:\n",
    "```python\n",
    "# YOUR CODE HERE (OPTION)\n",
    "```\n",
    "hoặc đối với markdown cell thì là:\n",
    "```markdown\n",
    "YOUR ANSWER HERE\n",
    "```\n",
    "Tất nhiên, khi làm thì bạn xóa dòng `raise NotImplementedError()` đi.\n",
    "Đối những phần yêu cầu code thì thường ở ngay phía dưới sẽ có một (hoặc một số) cell chứa các bộ test để phần nào giúp bạn biết đã code đúng hay chưa; nếu chạy cell này không có lỗi gì thì có nghĩa là qua được các bộ test. Trong một số trường hợp, các bộ test có thể sẽ không đầy đủ; nghĩa là, nếu không qua được test thì là code sai, nhưng nếu qua được test thì chưa chắc đã đúng hoàn toàn.\n",
    "\n",
    "Trong khi làm bài, bạn có thể cho in ra màn hình, tạo thêm các cell để test. Nhưng khi nộp bài thì bạn xóa các cell mà bạn tự tạo, xóa hoặc comment các câu lệnh in ra màn hình. Bạn lưu ý <font color=red>không được tự tiện xóa các cell hay sửa code của Thầy</font> (trừ những chỗ được phép sửa như đã nói ở trên).\n",
    "\n",
    "Trong khi làm bài, thường xuyên `Ctrl + S` để lưu lại bài làm của bạn, tránh mất mát thông tin.\n",
    "\n",
    "*Nên nhớ mục tiêu chính ở đây là <font color=green>học, học một cách chân thật</font>.  Bạn có thể thảo luận ý tưởng với bạn khác cũng như tham khảo các nguồn trên mạng, nhưng sau cùng <font color=green>code và bài làm phải là của bạn, dựa trên sự hiểu thật sự của bạn</font> (khi tham khảo các nguồn trên mạng thì bạn cần ghi rõ nguồn trong bài làm, và đương nhiên là bạn cũng không được phép đưa code và bài làm cho bạn khác xem). <font color=red>Nếu vi phạm những điều này thì có thể bạn sẽ bị 0 điểm cho toàn bộ môn học.</font>*\n",
    "\n",
    "**Cách nộp bài**\n",
    "\n",
    "Khi chấm bài, đầu tiên mình sẽ chọn `Kernel` - `Restart Kernel & Run All Cells` để restart và chạy tất cả các cell trong notebook của bạn; do đó, trước khi nộp bài, bạn nên chạy thử `Kernel` - `Restart Kernel & Run All Cells` để đảm bảo mọi chuyện diễn ra đúng như mong đợi.\n",
    "\n",
    "Sau đó, bạn tạo thư mục nộp bài theo cấu trúc sau:\n",
    "- Thư mục `MSSV` (ví dụ, nếu bạn có MSSV là 1234567 thì bạn đặt tên thư mục là `1234567`)\n",
    "    - File `HW2.ipynb` (không cần nộp các file khác)\n",
    "\n",
    "Cuối cùng, bạn nén thư mục `MSSV` này lại với định dạng nén là .zip (chứ không được là .rar hay các định dạng khác) và nộp ở link trên moodle. \\\n",
    "<font color=red>Bạn lưu ý tuân thủ chính xác qui định nộp bài này.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9ceffa-29ba-4bd8-92af-84f1973fdc78",
   "metadata": {},
   "source": [
    "## Kiểm tra môi trường code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77727362-3316-434f-a07f-c3421ee3efc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fbff69-dd69-4cb2-bdd3-6439cb51bfbe",
   "metadata": {},
   "source": [
    "Bạn nên thấy kết quả in ra là đường dẫn đến file chạy python của môi trường \"ml-env\" mà mình đã hướng dẫn bạn cài đặt ở HW0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed19c61-0536-421a-9539-ea5f41ae33da",
   "metadata": {},
   "source": [
    "## Nắm bài toán cần giải quyết của bài tập này\n",
    "\n",
    "Cho dữ liệu quan sát được (dữ liệu huấn luyện): \n",
    "$$\\{(\\textbf{x}^{(1)}, y^{(1)}), ..., (\\textbf{x}^{(N_{train})}, y^{(N_{train})})\\}$$\n",
    "\n",
    "Trong đó:\n",
    "\n",
    "- $\\textbf{x}^{(n)} \\in \\mathbb{R}^{784}$ là véc-tơ đầu vào chứa các giá trị pixel của một ảnh xám $28\\times28$, ảnh này là ảnh một chữ số viết tay nào đó (véc-tơ $784$ chiều được tạo từ ảnh xám $28\\times28$ bằng cách nối các dòng của ảnh xám lại với nhau)\n",
    "- $y^{(n)} \\in \\{0, 1, ..., 9\\}$ là đầu ra tương ứng, cho biết đây là chữ số nào\n",
    "\n",
    "Nhiệm vụ ở đây là tìm ra một (cách tiền xử lý và) mô hình (trong bài này: mô hình Softmax Regression) từ dữ liệu này sao cho (cách tiền xử lý và) mô hình này có thể nhận đầu vào là một ảnh-chữ-số-viết-tay *mới* (là một véc-tơ $\\in \\mathbb{R}^{784}$) và dự đoán đầu ra tương ứng (chữ số nào trong $\\{0, 1, 2, ..., 9\\}$) một cách *chính xác*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe3c1e8c-d9d8-48ad-9802-a8be7343d2fc",
   "metadata": {},
   "source": [
    "## Import các thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7073b4c1-98ae-4d25-865a-d9f5a60eefce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import gzip\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot') # Để hình vẽ đẹp hơn một xíu ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe8facb-b146-4460-803a-1eb7ff9ca969",
   "metadata": {},
   "source": [
    "Lưu ý: khi tính toán với mảng Numpy, bạn nên dùng các toán-tử/hàm/phương-thức mà Numpy đã cung cấp sẵn. Các toán-tử/hàm/phương-thức này làm trên nguyên mảng và ở bên dưới đã được tối ưu hóa; do đó, code sẽ ngắn gọn và chạy nhanh. Nếu bạn dùng vòng lặp for và làm với từng phần tử của mảng Numpy thì code sẽ dài và chạy chậm $\\to$ bạn sẽ bị trừ điểm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d2758d1-ccb2-4939-ba5f-6dba5d19a863",
   "metadata": {},
   "source": [
    "## Đọc dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2d7d29-48d7-40fd-9a75-b29f8963b5a4",
   "metadata": {},
   "source": [
    "Bộ dữ liệu mà ta sẽ dùng trong bài này là MNIST - bộ dữ liệu chữ số viết tay \"nổi tiếng\" trong cộng đồng làm Machine Learning. [Bộ MNIST gốc](http://yann.lecun.com/exdb/mnist/) gồm có: dữ liệu huấn luyện (60000 ảnh) và dữ liệu kiểm tra (10000 ảnh). Bộ MNIST mà ta sẽ dùng trong bài này (file \"mnist.pkl.gz\") gồm có: dữ liệu huấn luyện (50000 ảnh), dữ liệu validation (10000 ảnh), và dữ liệu kiểm tra (10000 ảnh); dữ liệu huấn luyện và validation ở đây được tạo ra bằng cách tách ngẫu nhiên dữ luyện huấn luyện gốc ra thành 2 phần theo tỉ lệ 5:1. \n",
    "\n",
    "Về mặt ý nghĩa thì dữ liệu validation và dữ liệu kiểm tra đều là dữ liệu mới ngoài dữ liệu huấn luyện. Dữ liệu validation giống như đề thi thử, có thể được thi một vài lần; còn dữ liệu kiểm tra giống như đề thi thật, để đảm bảo kết quả được khách quan thì chỉ được thi một lần duy nhất! Khi làm Machine Learning, ta thường muốn thử một số cách tiền xử lý + mô hình để chọn ra cách tiền xử lý + mô hình tốt nhất. Với mỗi cách tiền xử lý + mô hình, ta sẽ huấn luyện trên dữ liệu huấn luyện và đo độ lỗi dự đoán trên dữ liệu validation; cuối cùng ta sẽ chọn cách tiền xử lý + mô hình mà có độ lỗi dự đoán thấp nhất trên dữ liệu validation (ta không chọn dựa vào độ lỗi dự đoán trên dữ liệu huấn luyện vì có thể xảy ra trường hợp \"học vẹt\": cách tiền xử lý + mô hình có độ lỗi rất thấp trên dữ liệu huấn luyện nhưng lại có độ lỗi cao với dữ liệu mới ngoài dữ liệu huấn luyện). Khi đã chọn xong cách tiền xử lý + mô hình rồi thì ta sẽ đo một lần duy nhất độ lỗi dự đoán trên dữ liệu kiểm tra để có một ước lượng khách quan về độ lỗi thật sự! Nếu bạn nhìn vào độ lỗi dự đoán trên dữ liệu kiểm tra và quay lại điều chỉnh cách tiền xử lý + mô hình thì kết quả trên dữ liệu kiểm tra sẽ không còn sự khách quan nữa!\n",
    "\n",
    "Đoạn code dưới đây sẽ đọc dữ liệu từ file \"mnist.pkl.gz\" và lưu kết quả vào 6 mảng:\n",
    "\n",
    "- `train_X`, `train_y`\n",
    "- `val_X`, `val_y`\n",
    "- `test_X`, `test_y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85445e3b-6dce-4d17-8c75-2cdf31902f57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_mnist(mnist_file):\n",
    "    if os.path.isfile(mnist_file) == False:\n",
    "        mnist_file = os.path.join(os.path.expanduser('~'), 'data', 'mnist.pkl.gz')\n",
    "    \n",
    "    f = gzip.open(mnist_file, 'rb')\n",
    "    train_data, val_data, test_data = pickle.load(f, encoding='latin1')\n",
    "    f.close()\n",
    "    \n",
    "    train_X, train_Y = train_data\n",
    "    val_X, val_Y = val_data\n",
    "    test_X, test_Y = test_data    \n",
    "    \n",
    "    return train_X, train_Y, val_X, val_Y, test_X, test_Y\n",
    "\n",
    "# Bạn cần đặt file \"mnist.pkl.gz\" vào cùng thư mục với file notebook này,\n",
    "# hoặc bạn cũng có thể đặt ở thư mục tương ứng với câu lệnh này:\n",
    "# os.path.join(os.path.expanduser('~'), 'data')\n",
    "train_X, train_y, val_X, val_y, test_X, test_y = read_mnist('mnist.pkl.gz')\n",
    "print(f'Shape of train_X: {train_X.shape}, shape of train_y: {train_y.shape}')\n",
    "print(f'Shape of val_X:   {val_X.shape}, shape of val_y:   {val_y.shape}')\n",
    "print(f'Shape of test_X:  {test_X.shape}, shape of test_y:  {test_y.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace86f28-80c3-40a2-9540-2bc771fb9cb6",
   "metadata": {},
   "source": [
    "## Khám phá dữ liệu huấn luyện"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099fcbee-ef4c-4e25-981f-6d496c2d69c6",
   "metadata": {},
   "source": [
    "Đầu tiên, ta hãy xem thử min và max của `train_X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394d7905-7d70-4940-b845-261f55c33fda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(f'Min of train_X: {train_X.min()}, max of train_X: {train_X.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2eadedd-8a35-4e8d-8586-4888358f7440",
   "metadata": {},
   "source": [
    "Với ảnh xám thì giá trị của mỗi pixel thường sẽ nằm trong đoạn [0, 255] (với 0 là màu đen và 255 là màu trắng), hoặc đôi khi được chuẩn hóa về đoạn [0, 1] (với 0 là màu đen và 1 là màu trắng). Ở đây có vẻ giá trị pixel của ảnh xám của ta nằm trong đoạn [0, 1]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46549653-485d-41b5-b91c-5cf252fb7124",
   "metadata": {},
   "source": [
    "Tiếp theo, ta hãy thử xem mặt mũi của vài ảnh trong `train_X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a94fc50-4ade-4eaf-81f5-79c4ada1d743",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Bạn có thể chạy cell này nhiều lần để xem các ảnh ngẫu nhiên khác nhau\n",
    "n_rimages = 10; n_cimages = 10 \n",
    "padding = 2 \n",
    "canvas = 0.5 * np.ones((n_rimages * (28 + 2 * padding), n_cimages * (28 + 2 * padding)))\n",
    "rand_idxs = np.random.permutation(np.arange(len(train_X))[:n_rimages * n_cimages])\n",
    "for r in range(n_rimages):\n",
    "    for c in range(n_cimages):\n",
    "        i = r * n_cimages + c\n",
    "        image = train_X[rand_idxs[i]].reshape(28, 28)\n",
    "        temp1 = r * (28 + 2 * padding) + padding \n",
    "        temp2 = c * (28 + 2 * padding) + padding \n",
    "        canvas[temp1:temp1 + 28, temp2:temp2 + 28] = image\n",
    "plt.imshow(canvas, cmap='gray', vmin=0, vmax=1)\n",
    "plt.grid(None); plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08685f3c-9d7b-4375-841d-487869da1a6c",
   "metadata": {},
   "source": [
    "Tiếp theo, ta hãy xem các giá trị có thể có của `train_y` và số lượng của mỗi giá trị này."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007764a3-a643-40ac-be6c-ae733092e08c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "values, counts = np.unique(train_y, return_counts=True)\n",
    "for value, count in zip(values, counts):\n",
    "    print(f'Value: {value}, count: {count}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a020ebd9-3e89-42d8-b3cc-0b40fba13091",
   "metadata": {},
   "source": [
    "Như vậy là `train_y` có 10 giá trị có thể có ứng với 10 chữ số từ 0 đến 9. Và số lượng ảnh của mỗi chữ số cũng khá tương đương nhau. Tốt ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb6f806-ac87-4866-b78d-4c0f6ceb2fbd",
   "metadata": {},
   "source": [
    "## Tiền xử lý dữ liệu huấn luyện"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83071e7b-2c98-46b9-bf30-fbb8855bfae1",
   "metadata": {},
   "source": [
    "Tương tự như mô hình Linear Regression ở HW1, với mô hình Softmax Regression trong bài này thì đầu tiên ta cũng sẽ thêm cột toàn 1 vào đầu `train_X`; bằng cách này, những tính toán về sau sẽ được thuận tiện hơn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0e8b5d-c8f5-4722-8bd1-2b0524c0ebc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_ones(X):\n",
    "    return np.hstack((np.ones((len(X), 1)), X))\n",
    "\n",
    "# Gọi hàm add_ones để tiền xử lý train_X\n",
    "train_Z = add_ones(train_X)\n",
    "train_Z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f9fec7-a85b-4a6b-8395-31c9cce2d3ec",
   "metadata": {},
   "source": [
    "## Tìm mô hình Softmax Regression từ dữ liệu huấn luyện"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51d6b96-c45b-4b98-b367-d764dea2fdb9",
   "metadata": {},
   "source": [
    "Ta sẽ tìm bộ trọng số của mô hình Softmax Regression bằng cách cực tiểu hóa độ lỗi cross-entropy trên dữ liệu huấn luyện. Bạn có thể xem công thức tính độ lỗi cross-entropy ở trang 6 của slide \"HW2-Slide.pdf\" mà mình đính kèm. Ở đây, ta không thể giải ra trực tiếp bộ trọng số như ở mô hình Linear Regression, mà cần phải dùng một thuật toán cực tiểu hóa mà ban đầu sẽ khởi tạo đại bộ trọng số, rồi sẽ thực hiện nhiều vòng lặp, ở mỗi vòng lặp sẽ cập nhật bộ trọng số một ít để làm giảm độ lỗi trên dữ liệu huấn luyện. Trong bài này, ta sẽ cài đặt một thuật toán cực tiểu hóa đơn giản là Gradient Descent. Bạn có thể xem các bước của thuật toán Gradient Descent để tìm bộ trọng số của Softmax Regression ở trang 8-11 của slide \"HW2-Slide.pdf\". Theo đó thì ở mỗi vòng lặp, để tính gradient thì trước tiên ta sẽ cần tính các véc-tơ đầu ra của mô hình Softmax Regression ứng với các véc-tơ đầu vào của dữ liệu huấn luyện và bộ trọng số hiện tại.\n",
    "\n",
    "***Nhiệm vụ 1 của bạn (2đ):*** viết hàm `compute_smreg_output` để tính các véc-tơ đầu ra (hoặc các đầu ra) của mô hình Softmax Regression; ta sẽ dùng hàm này trong quá trình huấn luyện mô hình Softmax Regression (như đã nói ở trên) cũng như sau khi huấn huyện để dự đoán với các véc-tơ đầu vào mới.\n",
    "\n",
    "Hàm `compute_smreg_output` có các tham số đầu vào:\n",
    "- `W`: mảng chứa các trọng số của mô hình Softmax Regression, mảng này có shape là `(d+1, K)` với `d` là số lượng phần tử của véc-tơ đầu vào (khi chưa thêm 1 ở đầu) và `K` là số lượng lớp; với dữ liệu cụ thể của ta thì `d` bằng 784 và `K` bằng 10  \n",
    "- `X`: mảng chứa các véc-tơ đầu vào cần dự đoán, mảng này có shape là `(N, d+1)` với `N` là số lượng các véc-tơ đầu vào\n",
    "- `return_prob`: nếu cờ này bằng `True` thì với mỗi véc-tơ đầu vào, ta sẽ trả về một véc-tơ đầu ra cho biết xác xuất của các lớp; nếu cờ này bằng `False` thì với mỗi véc-tơ đầu vào, ta sẽ trả về một giá trị đầu ra cho biết lớp mà có xác suất lớn nhất\n",
    "\n",
    "Hàm `compute_smreg_output` sẽ trả về mảng chứa các véc-tơ đầu ra (hoặc các đầu ra) tương ứng với các véc-tơ đầu vào; nếu `return_prop` bằng True thì mảng trả về sẽ có shape `(N, K)`, còn nếu `return_prop` bằng `False` thì sẽ có shape `(N,)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2210e4f0-5115-4188-b7a8-e31f90cdb566",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "0e5703c47a59b4e5dd8b75ca0d27cf12",
     "grade": false,
     "grade_id": "cell-05d19f16c2fdf7f9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_smreg_output(W, X, return_prob=True):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929bd9fd-b5f0-42b3-b959-bbd4e80987aa",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b0cb2bdf493e5b559575dc7ee27380d7",
     "grade": true,
     "grade_id": "cell-ef833cf8032b23ea",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "# Tạo một mảng X với 4 dòng ứng với 4 véc-tơ đầu vào (đã thêm 1 ở đầu)\n",
    "X = np.array([[1.0, 0.9], \n",
    "              [1.0, 0.5], \n",
    "              [1.0, 0.4],\n",
    "              [1.0, 0.1]])\n",
    "# Tạo một mảng W gồm có 3 cột ứng với bộ trọng số của 3 lớp\n",
    "W = np.array([[ 0.3 ,  0.2 ,  0.5 ],\n",
    "              [-0.1 , -0.2 , -0.35]])\n",
    "# Kiểm tra hàm compute_smreg_output của bạn!\n",
    "predicted_Y = compute_smreg_output(W, X)\n",
    "assert predicted_Y.shape == (4, 3)\n",
    "assert str(predicted_Y[0][0].round(4)) == '0.3569'\n",
    "assert str(predicted_Y[1][0].round(4)) == '0.3403'\n",
    "assert str(predicted_Y[2][0].round(4)) == '0.3362'\n",
    "assert str(predicted_Y[3][0].round(4)) == '0.3239'\n",
    "predicted_y = compute_smreg_output(W, X, return_prob=False)\n",
    "assert predicted_y.shape == (4,)\n",
    "assert list(predicted_y) == [0, 2, 2, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d5447f-e41e-42b6-9920-fc7d394e8a1a",
   "metadata": {},
   "source": [
    "***Sau khi đã xong nhiệm vụ 1 thì bây giờ là nhiệm vụ 2 và cũng là nhiệm vụ chính của bạn (4đ):*** viết hàm `train_smreg` (trong hàm này thì bạn có thể dùng hàm `compute_smreg_output` mà bạn đã viết ở nhiệm vụ 1).\n",
    "\n",
    "Hàm `train_smreg` có các tham số đầu vào:\n",
    "- `X`: mảng chứa các véc-tơ đầu vào (đã được thêm 1 ở đầu) của dữ liệu huấn luyện, mảng này có shape là `(N, d+1)` với `N` là số lượng véc-tơ đầu vào của dữ liệu huấn luyện và `d` là số lượng phần tử của mỗi véc-tơ đầu vào (khi chưa thêm 1 ở đầu)\n",
    "- `y`: mảng chứa các đầu ra tương ứng với các véc-tơ đầu vào của dữ liệu huấn luyện, mảng này có shape là `(N,)`\n",
    "- `lr`: số thực > 0 cho biết hệ số học (learning rate) của thuật toán Gradient Descent\n",
    "- `max_epoch`: số nguyên > 0 cho biết số vòng lặp tối đa của thuật toán Gradient Descent (ví dụ, nếu `max_epoch` bằng 10 thì ta sẽ chạy Gradient Descent với 10 vòng lặp)\n",
    "- `initial_W`: mảng chứa các trọng số khởi tạo của mô hình Softmax Regression (ta sẽ chạy Gradient Descent từ các trọng số khởi tạo này), mảng này có shape là `(d+1, K)` với `K` là số lượng các lớp (với dữ liệu cụ thể của ta thì `K` bằng 10); nếu `initial_W` bằng `None` thì trong hàm `train_smreg` ta sẽ khởi tạo các trọng số của mô hình Softmax Regression với giá trị là 0 (với mô hình Softmax Regression thì ta khởi tạo như thế nào cũng được, ở đây ta thống nhất là khởi tạo với giá trị là 0 để thầy và trò sẽ ra cùng kết quả)\n",
    "\n",
    "Hàm `train_smreg` trả về:\n",
    "- Mảng chứa các trọng số tìm được của mô hình Softmax Regression, mảng này có shape là `(d+1, K)`\n",
    "- List chứa độ lỗi cross-entropy trên dữ liệu huấn luyện sau mỗi vòng lặp, list này gồm có `max_epoch` phần tử. Bạn xem công thức tính độ lỗi cross-entropy trên dữ liệu huấn luyện ở trang 6 của slide \"HW2-Slide.pdf\"\n",
    "\n",
    "Trong hàm `train_smreg` thì bước khó nhất là bước tính gradient. Bạn có thể xem công thức tính gradient ở trang 10 của slide \"HW2-Slide.pdf\". Cái khó và cũng là cái hay ở đây là từ công thức này, ta phải suy nghĩ ra cách code để tính gradient bằng các toán-tử/hàm/phương-thức của Numpy mà không dùng vòng lặp for, vì nếu dùng vòng lặp thì code sẽ dài và chạy chậm (với vòng lặp ngoài cùng Gradient Descent thì bạn được phép dùng vòng lặp để cài đặt). Mình sẽ giúp đỡ bạn một xíu bằng cách đưa ra một ví dụ cụ thể và bạn có thể dùng kiểm tra xem code tính gradient của bạn có đúng hay không trước khi đưa code này vào hàm `train_smreg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cbcc08-6485-49fa-936c-d1a7e483396d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Giả sử ta có mảng X với 4 dòng ứng với 4 véc-tơ đầu vào (đã thêm 1 ở đầu)\n",
    "X = np.array([[1.0, 0.9], \n",
    "              [1.0, 0.5], \n",
    "              [1.0, 0.4],\n",
    "              [1.0, 0.1]])\n",
    "# Và đây là mảng Y (viết hoa) với:\n",
    "# - 4 dòng ứng với 4 véc-tơ đầu ra dạng one-hot (ứng với 4 véc-tơ đầu vào của mảng X)\n",
    "# - 3 cột ứng với 3 lớp\n",
    "Y = np.array([[1, 0, 0], \n",
    "              [0, 1, 0], \n",
    "              [0, 0, 1], \n",
    "              [1, 0, 0]])\n",
    "# Và đây là mảng predicted_Y với 4 dòng ứng với 4 véc-tơ đầu ra dự đoán (véc-tơ \n",
    "# chứa xác suất của các lớp) của mô hình Softmax Regression với bộ trọng số hiện tại\n",
    "# (4 véc-tơ đầu ra dự đoán này ứng với 4 véc-tơ đầu vào của mảng X)\n",
    "predicted_Y = np.array([[0.3569, 0.2951, 0.348 ],\n",
    "                        [0.3403, 0.2929, 0.3668],\n",
    "                        [0.3362, 0.2923, 0.3715],\n",
    "                        [0.3239, 0.2902, 0.3859]])\n",
    "\n",
    "# Tính gradient từ X, Y, và predicted_Y (chỉ cần 1 dòng code ;-) )\n",
    "# grad = ... \n",
    "\n",
    "# Nếu bạn tính gradient đúng thì kết quả in ra của mảng grad sẽ là:\n",
    "# [[-0.160675   0.042625   0.11805  ]\n",
    "#  [-0.0854425  0.014495   0.0709475]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7dd9fd-3e91-4706-8b57-21a9ed2d2ab7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9387129e307d4ec48fe85ce5bf8bdf09",
     "grade": false,
     "grade_id": "cell-0721a0367e67f425",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ngoài hàm compute_smreg_output, nếu muốn thì bạn có thể viết thêm các hàm phụ \n",
    "# trợ khác cho hàm train_smreg\n",
    "# YOUR CODE HERE (OPTION)\n",
    "\n",
    "def train_smreg(X, y, lr, max_epoch, initial_W=None):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c017f0-bea5-46ee-91ca-852246f1468e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dea161dc3dd0e0da9a492ee709e3d688",
     "grade": true,
     "grade_id": "cell-a04f7182d6a35cb4",
     "locked": true,
     "points": 4,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "W, train_ces = train_smreg(train_Z, train_y, lr=0.3, max_epoch=3)\n",
    "assert W.shape == (785, 10)\n",
    "assert str(W[0, 0].round(4)) == '-0.011'\n",
    "assert len(train_ces) == 3\n",
    "assert str(np.round(train_ces[0], 4)) == '2.0074'\n",
    "assert str(np.round(train_ces[1], 4)) == '1.7753'\n",
    "assert str(np.round(train_ces[2], 4)) == '1.5914'\n",
    "W, train_ces = train_smreg(train_Z, train_y, lr=0.3, max_epoch=3, initial_W=W)\n",
    "assert W.shape == (785, 10)\n",
    "assert str(W[0, 0].round(4)) == '-0.0215'\n",
    "assert len(train_ces) == 3\n",
    "assert str(np.round(train_ces[0], 4)) == '1.4458'\n",
    "assert str(np.round(train_ces[1], 4)) == '1.3295'\n",
    "assert str(np.round(train_ces[2], 4)) == '1.2354'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51aafb53-148b-4ad8-a6d3-985756c13f27",
   "metadata": {},
   "source": [
    "Ở trên ta chỉ thử hàm `train_smreg` với `max_epoch` nhỏ (3) để có thể nhanh chóng kiểm tra tính đúng đắn của hàm `train_smreg`. Bây giờ mới là làm thật. Ta sẽ gọi `train_smreg` với `max_epoch` lớn. Tuy nhiên, ta sẽ cần chọn ra giá trị `lr` (learning rate) phù hợp để việc cực tiểu hóa của thuật toán Gradient Descent diễn ra một cách tốt đẹp. Để đỡ tốn thời gian, ta sẽ chia ra làm 2 giai đoạn. Ở giai đoạn đầu, ta sẽ gọi hàm `train_smreg` với `max_epoch` vừa vừa (100) và thử với các giá trị `lr`khác nhau (0.03, 0.3, 3). Sau khi quan sát kết quả, ta sẽ chọn ra giá trị `lr` phù hợp nhất, rồi qua giai đoạn 2: gọi tiếp hàm `train_smreg` với giá trị `lr` này và bộ trọng số tìm được trước đó và `max_epoch` lớn (400). Ta sẽ gọi bộ trọng số tìm được sau cùng là `W_1` (vì lúc sau ta sẽ thử một cách tiền xử lý + mô hình Softmax Regression khác, và ta sẽ gọi bộ trọng số tìm được là `W_2`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2965b305-c3c1-4737-8a38-a2b1178f975b",
   "metadata": {},
   "source": [
    "Đầu tiên là giai đoạn 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b781a076-184f-4354-a546-18f1888530aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "W_1a, train_ces_1a = train_smreg(train_Z, train_y, lr=0.03, max_epoch=100)\n",
    "W_1b, train_ces_1b = train_smreg(train_Z, train_y, lr=0.3, max_epoch=100)\n",
    "W_1c, train_ces_1c = train_smreg(train_Z, train_y, lr=3, max_epoch=100)\n",
    "\n",
    "plt.plot(np.log(train_ces_1a), label='lr=0.03', color='orange')\n",
    "plt.plot(np.log(train_ces_1b), label='lr=0.3', color='green')\n",
    "plt.plot(np.log(train_ces_1c), label='lr=3', color='red')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Log (for clarity) of training cross-entropy')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743790f7-7916-446c-813b-249dc5873056",
   "metadata": {},
   "source": [
    "***Nhiệm vụ của bạn (1đ):*** quan sát kết quả và giải thích tại sao kết quả lại như vậy (nếu bạn không biết tại sao thì cứ nói là không biết tại sao)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc7d9ed-322a-438b-9643-66ee7dafd19c",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4b42954bd3fe3c346d09815f441212f3",
     "grade": true,
     "grade_id": "cell-5dc295653765d5ae",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bd2e6b-6935-4979-81f3-09117ecf4adf",
   "metadata": {},
   "source": [
    "Nếu code của bạn đúng thì bạn sẽ thấy `lr=0.3` là giá trị phù hợp nhất. Tiếp theo, ta sẽ qua giai đoạn 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fa0967-b28e-4edc-a4b8-9402d0f42040",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_1, train_ces = train_smreg(train_Z, train_y, lr=0.3, max_epoch=400, initial_W=W_1b)\n",
    "\n",
    "plt.plot(np.log(train_ces), color='green')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Log (for clarity) of training cross-entropy');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b43ccfb-e42f-4fb7-a7b7-d5c3af2399c7",
   "metadata": {},
   "source": [
    "Có vẻ là nếu ta tiếp tục chạy thì độ lỗi cross-entropy sẽ còn giảm nữa, nhưng thôi, trong bài này ta sẽ tạm dừng ở đây vì laptop của mình bắt đầu kêu rồi ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad130a5-8136-4ca7-b921-99b018cfcb1d",
   "metadata": {},
   "source": [
    "## Dùng mô hình Softmax Regression tìm được để dự đoán với dữ liệu huấn luyện và đánh giá kết quả"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5725b9c4-bbe6-4d20-adf9-e9bdecaed559",
   "metadata": {},
   "source": [
    "Đầu tiên, ta sẽ dùng mô hình Softmax Regression tìm được để dự đoán với dữ liệu huấn luyện."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78354c2-cd51-484c-b1e7-308698a9f183",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_train_y = compute_smreg_output(W_1, train_Z, return_prob=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63e1b95-37be-4bd8-8d22-12c47d1f0fe2",
   "metadata": {},
   "source": [
    "Tiếp theo, ta sẽ so sánh các đầu ra dự đoán với các đầu ra đúng và đánh giá kết quả.\n",
    "\n",
    "***Nhiệm vụ của bạn (1đ):*** viết hàm `compute_mbe` để tính độ lỗi MBE - Mean Binary Error; độ lỗi này là một số thực từ 0 đến 100 cho biết tỉ lệ phần trăm các mẫu bị dự đoán sai (độ lỗi cross-entropy giúp dễ cực tiểu hóa hơn trong quá trình huấn luyện, nhưng khi đánh giá thì độ lỗi MBE sẽ giúp con người dễ cảm nhận hơn).\n",
    "\n",
    "Hàm này nhận vào các tham số:\n",
    "- `predicted_y`: mảng chứa các đầu ra dự đoán, có shape là `(N,)`\n",
    "- `y`: mảng chứa các đầu ra đúng, cũng có shape là `(N,)`\n",
    "\n",
    "Hàm này trả về: số thực từ 0 đến 100 cho biết độ lỗi MBE giữa `predicted_y` và `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896331f9-1ded-4809-b191-394f0b54e755",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dcef45a58ebf1055c3499f004774336f",
     "grade": false,
     "grade_id": "cell-ad6eb020530af7e9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_mbe(predicted_y, y):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()\n",
    "\n",
    "# Gọi hàm compute_mbe để tính độ lỗi giữa predicted_train_y và train_y\n",
    "train_mbe = compute_mbe(predicted_train_y, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede66cb2-ec8b-4e37-bba4-52f794b5b98c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ed5c5423ca3a8c63ba2f07a76804c138",
     "grade": true,
     "grade_id": "cell-fee1b637d6b34faf",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert str(np.round(train_mbe, 4)) == '9.192'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99250d0-1c9f-4789-b632-6449b3baad33",
   "metadata": {},
   "source": [
    "## Tiền xử lý dữ liệu validation, dùng mô hình Softmax Regression tìm được để dự đoán với dữ liệu validation và đánh giá kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a7a007-186b-472b-9724-09d1417ac849",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_Z = add_ones(val_X)\n",
    "predicted_val_y = compute_smreg_output(W_1, val_Z, return_prob=False)\n",
    "val_mbe = compute_mbe(predicted_val_y, val_y)\n",
    "assert str(np.round(val_mbe, 4)) == '8.36'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a298e9fd-a9bd-4593-a937-45ce22b257e3",
   "metadata": {},
   "source": [
    "## Đưa ra ý tưởng cải tiến"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e301768-8bd2-4dce-afbb-1559b73250d3",
   "metadata": {},
   "source": [
    "Ta thấy hiện giờ mô hình Softmax Regression tìm được của ta có độ lỗi khá cao trên cả dữ liệu huấn luyện lẫn dữ liệu validation. Nếu ta có thể làm giảm độ lỗi trên dữ liệu huấn luyện thì có khả năng độ lỗi trên dữ liệu validation cũng sẽ giảm theo. Một cách để làm giảm độ lỗi trên dữ liệu huấn luyện là tăng thêm số lượng vòng lặp của thuật toán Gradient Descent. Tuy nhiên, sau cùng thì mô hình Softmax Regression vẫn là một mô hình đơn giản. Do đó, ở đây, mình muốn đưa ra một cách khác mà có thể giúp làm giảm độ lỗi trên dữ liệu huấn luyện của mô hình Softmax Regression - một mô hình đơn giản. Cách này tương tự như cách mà ta đã làm ở HW1: suy nghĩ để thiết kế ra véc-tơ đầu vào $\\textbf{z}$ thay cho véc-tơ đầu vào $\\textbf{x}$ sao cho véc-tơ đầu vào $\\textbf{z}$ sẽ giúp mô hình Softmax Regression dự đoán đầu ra $y$ tốt hơn hơn so với véc-tơ đầu vào $\\textbf{x}$. Cụ thể ở đây, ta sẽ thử một cách thiết kế đơn giản cho véc-tơ đầu vào $\\textbf{z}$: $\\textbf{z}$ là $\\textbf{x}$ (chứa các giá trị pixel) được bổ sung thêm 2 đặc trưng là \"intensity\" và \"symmetry\".\n",
    "\n",
    "- \"intensity\" của một ảnh cho biết giá trị pixel trung bình của ảnh; đặc trưng này có thể giúp ích cho việc phân tách giữa các chữ số vì có các chữ số có ít đường nét (\"intensity\" thấp) và có các chữ số có nhiều đường nét (\"intensity\" cao) \n",
    "- \"symmetry\" của ảnh cho biết mức độ đối xứng của ảnh; đặc trưng này cũng có thể giúp ích cho việc phân tách giữa các chữ số vì có các chữ số có mức độ đối xứng thấp và có các chữ số có mức độ đối xứng cao. Cụ thể, \"symmetry\" của ảnh được tính như sau:\n",
    "    - Lấy ảnh trừ đi ảnh lật theo chiều ngang, lấy trị tuyệt đối, rồi tính trung bình. Gọi kết quả tính được là s1\n",
    "    - Lấy ảnh trừ đi ảnh lật theo chiều dọc, lấy trị tuyệt đối, rồi tính trung bình. Gọi kết quả tính được là s2\n",
    "    - symmetry = - (s1 + s2) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e0cb9c-4777-4cbe-bff3-56b4ddf4ff22",
   "metadata": {},
   "source": [
    "## Tiền xử lý dữ liệu huấn luyện"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eac815ff-80be-4c53-8d45-be192e5bb694",
   "metadata": {},
   "source": [
    "Ta sẽ tiền xử lý `train_X` bằng cách thêm vào cuối `train_X` 2 cột ứng với 2 đặc trưng đã mô tả ở trên là \"intensity\" và \"symmetry\". Ta cũng sẽ chuẩn hóa để đưa các giá trị của 2 cột này về đoạn [0, 1] bằng cách: lấy mỗi cột trừ cho min-của-cột rồi chia cho (max-của-cột trừ cho min-của-cột); ở đây, max-của-cột và min-của-cột là max và min của cột ban đầu khi chưa đụng chạm gì cả. Ta chuẩn hóa như này để miền giá trị của 2 cột này tương tự với miền giá trị của các cột trước đó (chứa các giá trị pixel) của `train_X`; việc các cột có miền giá trị tương tự nhau thường sẽ giúp cho thuật toán Gradient Descent hội tụ nhanh hơn. Sau khi đã thêm 2 cột \"intensity\" và \"symmetry\" (đã chuẩn hóa) vào cuối `train_X` thì ta sẽ thêm cột 1 vào đầu `train_X`.\n",
    "\n",
    "***Nhiệm vụ của bạn (2đ):*** viết hàm `add_features` để thêm 2 cột \"intensity\" và \"symmetry\" (đã chuẩn hóa). \n",
    "\n",
    "Hàm này có các tham số đầu vào:\n",
    "- `X`: mảng chứa các véc-tơ đầu vào (chưa thêm 1 ở đầu), mảng này có shape là `(N, d)` với `N` là số lượng các véc-tơ đầu vào và `d` là số lượng phần tử của mỗi véc-tơ đầu vào \n",
    "- `mins` và `maxs`: 2 mảng chứa min và max của 2 cột \"intensity\" và \"symmetry\" (khi chưa chuẩn hóa) của *dữ liệu huấn luyện*, mỗi mảng có shape là `(2,)`. Khi gọi hàm này với dữ liệu huấn luyện thì `mins` và `maxs` sẽ bằng `None`, và bên trong hàm sẽ tính `mins` và `maxs` từ dữ liệu huấn luyện, và dùng `mins` và `maxs` này để chuẩn hóa. Khi gọi hàm này với dữ liệu mới ngoài dữ liệu huấn luyện thì cách làm chuẩn là sẽ truyền vào `mins` và `maxs` được tính từ *dữ liệu huấn luyện*, và dùng `mins` và `maxs` này để chuẩn hóa\n",
    "\n",
    "Hàm này trả về: mảng `X` được thêm vào cuối 2 cột là \"intensity\" và \"symmetry\" (2 cột này đã được chuẩn hóa về [0, 1]), mảng kết quả này có shape là `(N, d+2)`; nếu `mins` và `maxs` truyền vào bằng None thì: ngoài mảng `X` được thêm vào cuối 2 cột mới, còn trả về thêm `mins` và `maxs` được tính từ dữ liệu (`mins` và `maxs` là mảng có shape là `(2,)`).\n",
    "\n",
    "Để đơn giản cho bạn thì mình cho phép bạn dùng vòng lặp trong hàm `add_features` để duyệt qua các ảnh trong mảng `X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e086bd2b-8024-45fe-9427-567e319d4db7",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f9378477a9d0ca4df8c46892af27b58c",
     "grade": false,
     "grade_id": "cell-6dca8835bd4c5e54",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def add_features(X, mins=None, maxs=None):\n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2f09ba-dd3f-4666-8500-81492c7ed21a",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1a9db600ee844748bd7aaf07c3cfebd9",
     "grade": true,
     "grade_id": "cell-808cfc63f2c948a1",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TEST\n",
    "X = train_X[:5]\n",
    "Z, mins, maxs = add_features(X)\n",
    "assert Z.shape == (5, 786)\n",
    "assert str(Z[0, -2].round(4)) == '0.7443'\n",
    "assert str(Z[0, -1].round(4)) == '0.44'\n",
    "assert mins.shape == (2,)\n",
    "assert str(mins[0].round(4)) == '0.0854'\n",
    "assert str(mins[1].round(4)) == '-0.2051'\n",
    "assert maxs.shape == (2,)\n",
    "assert str(maxs[0].round(4)) == '0.1549'\n",
    "assert str(maxs[1].round(4)) == '-0.1427'\n",
    "\n",
    "X = val_X[:5]\n",
    "Z = add_features(X, mins, maxs)\n",
    "assert Z.shape == (5, 786)\n",
    "assert str(Z[0, -2].round(4)) == '0.3761'\n",
    "assert str(Z[0, -1].round(4)) == '1.9915'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437a5069-5cf4-42c7-bbba-f42ac68d2355",
   "metadata": {},
   "source": [
    "Ở trên, ta chỉ thử với dữ liệu nhỏ để nhanh chóng kiểm tra tính đúng đắn của hàm `add_features`. Bây giờ ta mới làm thật: gọi hàm `add_features` rồi `add_ones` để tiền xử lý `train_X`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c345b1-6160-4e1c-99ab-fd423aa805dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Z, mins_for_add_features, maxs_for_add_features = add_features(train_X)\n",
    "train_Z = add_ones(train_Z)\n",
    "train_Z.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dce70a9-8d06-4235-8d52-898d11cfc288",
   "metadata": {},
   "source": [
    "## Tìm mô hình Softmax Regression từ dữ liệu huấn luyện"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bebae3-74aa-49ca-8db5-493cc6f8f9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_2, train_ces = train_smreg(train_Z, train_y, lr=0.3, max_epoch=500)\n",
    "\n",
    "plt.plot(np.log(train_ces), color='green')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Log (for clarity) of training cross-entropy');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dac548-342e-43cf-9e34-717f7cb43698",
   "metadata": {},
   "source": [
    "## Dùng mô hình Softmax Regression tìm được để dự đoán với dữ liệu huấn luyện và đánh giá kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3009eb78-d8c9-419e-a18a-d9165a79f94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_train_y = compute_smreg_output(W_2, train_Z, return_prob=False)\n",
    "train_mbe = compute_mbe(predicted_train_y, train_y)\n",
    "assert str(np.round(train_mbe, 4)) == '9.116'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e30c26-4240-4a05-a154-ebaf71e8aef4",
   "metadata": {},
   "source": [
    "Như vậy là độ lỗi MBE trên dữ liệu huấn luyện giảm từ 9.192 xướng 9.116. Hmm ... giảm không đáng kể (chắc là do cách thiết kế véc-tơ đầu vào $\\textbf{z}$ của ta còn đơn giản), nhưng dù sao cũng có giảm ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74ef03b-82a7-48a0-bd8b-4abacd1c22d9",
   "metadata": {},
   "source": [
    "## Tiền xử lý dữ liệu validation, dùng mô hình Softmax Regression tìm được để dự đoán với dữ liệu validation và đánh giá kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20a2839-7a9a-462a-83b3-d5ec31ca1cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_Z = add_ones(add_features(val_X, mins_for_add_features, maxs_for_add_features))\n",
    "predicted_val_y = compute_smreg_output(W_2, val_Z, return_prob=False)\n",
    "val_mbe = compute_mbe(predicted_val_y, val_y)\n",
    "assert str(np.round(val_mbe, 4)) == '8.27'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06f0cd1-881f-47ec-b868-293ec8ba15a3",
   "metadata": {},
   "source": [
    "Độ lỗi MBE trên dữ liệu validation cũng giảm theo: giảm từ 8.36 xuống 8.27."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931ca838-76da-4449-b6d3-4973b2049deb",
   "metadata": {},
   "source": [
    "## Chọn ra cách tiền xử lý + mô hình Softmax Regression sau cùng là cách tiền xử lý + mô hình Softmax Regression mà có độ lỗi dự đoán thấp nhất trên dữ liệu validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cd1384-d877-434e-9a4d-49eb9308f6e1",
   "metadata": {},
   "source": [
    "Như vậy ta sẽ chọn cách tiền xử lý là `add_ones(add_features(..., mins_for_add_features, maxs_for_add_features))` và mô hình Softmax Regression có bộ trọng số là `W_2`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e83b9be2-a1dc-4961-b0ce-ec0f922b8e6b",
   "metadata": {},
   "source": [
    "## Dùng cách tiền xử lý + mô hình Softmax Regression sau cùng để đi thi thật!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965f157d-21de-4047-acdc-d9bde5544b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Z = add_ones(add_features(test_X, mins_for_add_features, maxs_for_add_features))\n",
    "predicted_test_y = compute_smreg_output(W_2, test_Z, return_prob=False)\n",
    "test_mbe = compute_mbe(predicted_test_y, test_y)\n",
    "assert str(np.round(test_mbe, 4)) == '8.6'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7555ed7-4c1c-4831-b1f3-f2355283206c",
   "metadata": {},
   "source": [
    "Giờ thì đi ngủ được rồi ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
