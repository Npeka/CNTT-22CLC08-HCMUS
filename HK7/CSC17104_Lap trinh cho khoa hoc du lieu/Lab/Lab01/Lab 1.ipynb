{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2204e0e2",
   "metadata": {},
   "source": [
    "# Lab 1: Linux commands & Python\n",
    "\n",
    "(Last update: 16/10/2023)\n",
    "\n",
    "Name:\n",
    "\n",
    "Student ID:\n",
    "\n",
    "---\n",
    "\n",
    "**Abstract**: This assignment tests your Python and Linux command skills. It also provides a general process for you to start a data project: Collect data $\\to$ Preprocess data $\\to$ Explore the meaning of data $\\to$ Mine insights from data.\n",
    "\n",
    "\n",
    "## 0. Instructions for doing and submitting assignment\n",
    "\n",
    "**How to do your assignment**\n",
    "\n",
    "You will do your assignment directly on this notebook file. First, you fill your name and student code at the beginning of the file. In this file, you will write your code when you see the following lines of code:\n",
    "```python\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "```\n",
    "\n",
    "For optional coding parts, there will be:\n",
    "```python\n",
    "# YOUR CODE HERE (OPTION)\n",
    "```\n",
    "\n",
    "For markdown cell, there will be:\n",
    "```markdown\n",
    "YOUR ANSWER HERE\n",
    "```\n",
    "\n",
    "Of course, you have to remove the `raise NotImplementedError()` statement when you finish.\n",
    "\n",
    "For coding parts, there are often cells below to help you check your answers. You will pass the test if there are no errors when you run the test cells. In some cases, the tests are insufficient. That means if you do not pass the test, your answer is definitely wrong somewhere, but if you pass the test, your answer may still be incorrect.\n",
    "\n",
    "While doing the assignment, you should print out the output and create more cells for testing. But you have to remove all of them (comment your print-out codes, delete the cell created by you) when you submit your code. <font color=red>Do not remove or edit my cells</font> (except for the aforementioned cells).\n",
    "\n",
    "Keep your code clean and clear by using meaningful variable names and comments, not write too-long coding lines.\n",
    "Press `Ctrl + S` right after editing.\n",
    "\n",
    "Keep it real: The reason why you are here is to <font color=green>study, really study</font>. I highly recommend that you discuss your idea with your friends and <font color=green>write your own code based on your own knowledge</font>. <font color=red>Copy means zero.</font>\n",
    "\n",
    "**How to submit your assignment**\n",
    "\n",
    "When grading your assignment, I will choose `Kernel` - `Restart & Run All` in order to restart the kernel and run all cells in your notebook. Therefore, you should do that before submitting to ensure that the outputs are all as expected.\n",
    "\n",
    "After that, rename the notebook as `<Student ID>.ipynb`. For example, if your student code is 1234567, then your notebook is `1234567.ipynb`.\n",
    "\n",
    "Finally, submit your notebook file on Moodle. <font color=red>Please strictly follow the submission rules.</font>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f40065",
   "metadata": {},
   "source": [
    "## 1. Programming environment\n",
    "\n",
    "- You will re-use the Linux environment setup in Lab 0 - WarmUp. Don't forget to start your coding environment (`conda activate min_ds-env`) before doing your assignment.\n",
    "- Use Jupyter notebook or Jupyter lab, <font color=red>not Google Colab</font> (I can not grade you well on Google Colab) to edit your `*.ipynb` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9130eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2529136",
   "metadata": {},
   "source": [
    "- Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8c0627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "# YOUR CODE HERE (OPTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706a3de5",
   "metadata": {},
   "source": [
    "## 2. Data collection\n",
    "\n",
    "- You are required to do the following tasks using Linux command:\n",
    "    - Create a folder named `./data`\n",
    "    - Collect data from the the links that were specified in `links.txt` and save to `./data` using `wget`\n",
    "    - After collecting data, rename your data as `data_2019.csv`, `data_2018.csv` and `guidance.csv` using `mv`\n",
    "    - List all the file contained in `./data` using `ls`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca2bdf3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e264f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3dd33c",
   "metadata": {},
   "source": [
    "## 3. Data exploring & Data preprocessing\n",
    "\n",
    "### 3.0. Read data\n",
    "\n",
    "- First, I suggest you check the downloaded data by yourself before handing on the code. What kind of the data that you have just downloaded? What is the meaning of each file?\n",
    "\n",
    "YOUR ANSWER HERE: They are tabular data, which contain information about traffic accidents in UK from 2018 to 2019. Additionally, there is a file that explains the notions in 2 data files.\n",
    "\n",
    "- After checking the data, design a function named `read_data` with the name of data file as parameter, which returns a dictionary. Each element of this dictionary follows:\n",
    "    - Key: Name of the columns\n",
    "    - Value: Lists which contains the data of the coresponding columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c58962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    # # YOUR CODE HERE\n",
    "    # raise NotImplementedError()\n",
    "\n",
    "data_2018 = read_data('./data/data_2018.csv')\n",
    "data_2019 = read_data('./data/data_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bcd3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert set(data_2018.keys()) == set(['Accident Fields_Reference Number', 'Grid Ref: Easting', 'Grid Ref: Northing', 'Number of Vehicles', 'Accident Date', 'Time (24hr)', '1st Road Class', '1st Road Class & No', 'Road Surface', 'Lighting Conditions', 'Weather Conditions', 'Local Authority', 'Vehicle Fields_Reference Number', 'Vehicle Number', 'Type of Vehicle', 'Casualty Fields_Reference Number', 'Casualty Veh No', 'Casualty Class', 'Casualty Severity', 'Sex of Casualty', 'Age of Casualty'])\n",
    "assert set(data_2019.keys()) == set(['Reference Number', 'Grid Ref: Easting', 'Grid Ref: Northing', 'Number of Vehicles', 'Accident Date', 'Time (24hr)', '1st Road Class', '1st Road Class & No', 'Road Surface', 'Lighting Conditions', 'Weather Conditions', 'Local Authority', 'Vehicle Number', 'Type of Vehicle', 'Casualty Class', 'Casualty Severity', 'Sex of Casualty', 'Age of Casualty'])\n",
    "\n",
    "id_col_len = len(data_2018['Accident Fields_Reference Number'])\n",
    "for col_name in data_2018:\n",
    "    assert len(data_2018[col_name]) == id_col_len\n",
    "    \n",
    "id_col_len = len(data_2019['Reference Number'])\n",
    "for col_name in data_2019:\n",
    "    assert len(data_2019[col_name]) == id_col_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9682b5a",
   "metadata": {},
   "source": [
    "### 3.1. The meaning of each column/row\n",
    "\n",
    "- Please refer to `./data/guidance.csv` in order to get the meaning of each column\n",
    "- Each row corresponds to an accident with a unique reference number\n",
    "- Compute the number of rows and columns and assign to `num_rows_2018`, `num_cols_2018`, `num_rows_2019`, `num_cols_2019`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337fe67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d7ccbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert (num_rows_2018, num_cols_2018, num_rows_2019, num_cols_2019) == (1995, 21, 1907, 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79445930",
   "metadata": {},
   "source": [
    "### 3.2. Duplicated columns\n",
    "\n",
    "- Observe the data in 2018, you can see that columns `Accident Fields_Reference Number`, `Vehicle Fields_Reference Number` and `Casualty Fields_Reference Number` seem to contain quite similar data.\n",
    "\n",
    "- Additionally, columns `Number of Vehicles` and `Vehicle Number` in `data_2018` and `data_2019` also look quite similar.\n",
    "\n",
    "- In order to make sure of these hypothesises, you have to check these columns. Your mission is to design a function named `check_similarity` in order to check the similarity (in percentage) of 2 given columns.\n",
    "- The percentage of similarity is computed by dividing the number of similar samples to total samples. `check_similarity` return a number illustrating the similarity of 2 columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021bf341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_similarity(data, col_name_1, col_name_2):\n",
    "    # # YOUR CODE HERE\n",
    "    # raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0151d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert round(check_similarity(data_2018, 'Accident Fields_Reference Number', 'Vehicle Fields_Reference Number'),5) == 1.\n",
    "assert round(check_similarity(data_2018, 'Accident Fields_Reference Number', 'Casualty Fields_Reference Number'),5) == 1.\n",
    "assert round(check_similarity(data_2018, 'Number of Vehicles', 'Vehicle Number'), 5) == 0.65213\n",
    "assert round(check_similarity(data_2019, 'Number of Vehicles', 'Vehicle Number'), 5) == 0.67541"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2f8541",
   "metadata": {},
   "source": [
    "- Therefore, column `Accident Fields_Reference Number`, `Vehicle Fields_Reference Number` and `Casualty Fields_Reference Number` contain the same data. We have to remove 2 of them.\n",
    "- It could be noise for us to analyze 2 columns with more than 65% similarity, so I also decide to remove `Vehicle Number`.\n",
    "- Since removing an element from a dictionary is a really hard task for beginner, I will help you on that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbda0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del data_2018['Vehicle Fields_Reference Number'], data_2018['Casualty Fields_Reference Number']\n",
    "del data_2019['Vehicle Number'], data_2018['Vehicle Number']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5608af9",
   "metadata": {},
   "source": [
    "### 3.3. Data merging & Data checking\n",
    "\n",
    "- In order for us to conveniently analyze the data, we should merge 2 data sets into 1.\n",
    "- Compare the columns of 2 data sets, you can see that there are some unmergeable columns:\n",
    "    - Column `Casualty Veh No` in `data_2018`: `data_2019` does not have one, so we have to remove this column from `data_2018`\n",
    "    - Column `Accident Fields_Reference Number` in `data_2018` should be changed to `Reference Number`\n",
    "- I will help you on these 2 tasks, then you will merge 2 data sets into `data_18_19`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6890cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete `Casualty Veh No` in data_2018\n",
    "del data_2018['Casualty Veh No']\n",
    "\n",
    "# rename\n",
    "data_2018['Reference Number'] = data_2018.pop('Accident Fields_Reference Number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21686b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert set(data_2018.keys()) == set(data_2019.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc2d9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de119d69",
   "metadata": {},
   "source": [
    "- After merging 2 data sets, you have to check whether there is any duplicated row based on the ID of each case. If there is, it should be removed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93463312",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_col = data_18_19['Reference Number']\n",
    "num_duplicated = len(id_col) - len(set(id_col))\n",
    "\n",
    "print(f'Duplicated rows: {\"True\" if num_duplicated > 0 else \"False\"}. Number of duplicated rows: {num_duplicated}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d00743",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36593124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert set(data_18_19.keys()) == set(data_2018.keys())\n",
    "assert len(set(data_18_19['Reference Number'])) == len(data_18_19['Reference Number'])\n",
    "assert len(data_18_19['1st Road Class']) == 2998"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997ba941",
   "metadata": {},
   "source": [
    "- You also have to check if there is any missing data. For missing data, I suggest you to fill in since there are a lot of methods to handle it. But if the missing data for a column becomes too much (e.g. more than 50%), you should consider to remove the column out of the dataset.\n",
    "\n",
    "- In this assignment, you will check missing data for each column. Result will be stored in a dictionary named `check_missing_data` which the key is column name and the value is `True` (some data is missing), `False` (no missing data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4723c412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a19f7ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert set(check_missing_data.keys()) == set(data_18_19.keys())\n",
    "for col in check_missing_data.keys():\n",
    "    assert check_missing_data[col] == False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a176b4f5",
   "metadata": {},
   "source": [
    "### 3.4. Data conversion\n",
    "\n",
    "- Obverse the datatype of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1eba91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in data_18_19.keys():\n",
    "    print(f'{col:25} {type(data_18_19[col][0])}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa821d4d",
   "metadata": {},
   "source": [
    "- Before moving to analyzing the dataset, the datatype of each column should be correct.\n",
    "- Based on `./data/guidance.csv` and research on the Internet:\n",
    "    - `Grid Ref` values are coordinate location in UK format $\\to$ Datatype: int\n",
    "    - `Number of Vehicles`: int\n",
    "    - `Accident Date`: datetime\n",
    "    - `Time (24hr)`: datetime\n",
    "    - `Age of Casualty`: int\n",
    "    - `1st Road Class`: str\n",
    "    - Rest: str\n",
    "    \n",
    "- In reallife project, you have to convert all columns into their correct datatype before doing anything else. But in this assignment, you are just required to merge `Time (24hr)` and `Accident Date` into column `Full time` with the correct datatype (datetime). After merging, delete `Time (24hr)` and `Accident Date`.\n",
    "    - The format of `Time (24hr)`: `hhmm`\n",
    "    - The format of `Accident Date`: `dd/mm/yyyy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bb8ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e16a1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST\n",
    "assert set(data_18_19.keys()) == set(['Grid Ref: Easting', 'Grid Ref: Northing', 'Number of Vehicles', '1st Road Class', '1st Road Class & No', 'Road Surface', 'Lighting Conditions', 'Weather Conditions', 'Local Authority', 'Type of Vehicle', 'Casualty Class', 'Casualty Severity', 'Sex of Casualty', 'Age of Casualty', 'Reference Number', 'Full time'])\n",
    "assert type(data_18_19['Full time'][0]) == datetime.datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983c1aec",
   "metadata": {},
   "source": [
    "- Looks like values in the `Local Authority` column are all the same\n",
    "- You need to count the number of distinct values of the `Local Authority` column\n",
    "- If all values in the `Local Authority` are the same, delete that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e272e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35de2a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert num_distinct_authority == 1\n",
    "assert 'Local Authority' not in data_18_19.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2d692b",
   "metadata": {},
   "source": [
    "## 4. Questions proposing & answering\n",
    "\n",
    "- In this section, we are going to propose 2 questions that can be answered by data. I will propose 1 question. The other one will be your task.\n",
    "- Note that answering these questions should give us some insight or useful information about traffic in UK.\n",
    "\n",
    "### 4.1. Question #1\n",
    "\n",
    "- How many accidents are there in each day of a week (Mon $\\to$ Sun) and in each hour of a day (0 $\\to$ 23)?\n",
    "- Meaning: Warn people to be careful when participating in traffic during those hours\n",
    "- Answer:\n",
    "    - Firstly, you will create a `matrix_` size $7\\times24$ which each element indicates he number of accidents during a certain hour of a certain day of the week. E.g. `matrix_[1][7]` indicates the number of accidents from 7h00m to 7h59m of Tuesday\n",
    "    - Then, you will fill in the matrix based on the column `Full time` that you have just created\n",
    "    - Finally, I will help you visualize the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed813b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # YOUR CODE HERE\n",
    "# raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dc1b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize\n",
    "# !pip install seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "day_of_week = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "ax = sns.heatmap(matrix_, linewidths=.5, yticklabels = day_of_week)\n",
    "ax.set_xlabel('Thời gian')\n",
    "ax.set_ylabel('Ngày trong tuần')\n",
    "ax.set_title('Thống kê tai nạn tại các khung giờ của các ngày trong tuần')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88a291e",
   "metadata": {},
   "source": [
    "### 4.2. Question #2\n",
    "\n",
    "YOUR ANSWER HERE\n",
    "\n",
    "- Question:\n",
    "- Meaning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab5676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
